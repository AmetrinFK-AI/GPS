# streamlit_app.py
# –¢–æ–ª—å–∫–æ OpenStreetMap. –í–°–ï —Ç–æ—á–∫–∏ –Ω–∞ –∫–∞—Ä—Ç–µ –∏ –ß–Å–¢–ö–ê–Ø –ù–£–ú–ï–†–ê–¶–ò–Ø.
# CSV –∏–∑ —Ç–≤–æ–µ–≥–æ —Ñ–∞–π–ª–∞: ['timestamp', 'latlng', 'odometer'] ‚Äî latlng -> lat, lon.

import io
import re
import json
import math
from typing import Optional, Tuple

import numpy as np
import pandas as pd
import streamlit as st
import folium
from folium.plugins import AntPath, TimestampedGeoJson, PolyLineTextPath
from streamlit_folium import st_folium

# ---------------------------
# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
# ---------------------------

def haversine_km(lat1, lon1, lat2, lon2):
    R = 6371.0088
    phi1 = math.radians(lat1); phi2 = math.radians(lat2)
    dphi = math.radians(lat2 - lat1); dlambda = math.radians(lon2 - lon1)
    a = math.sin(dphi/2)**2 + math.cos(phi1)*math.cos(phi2)*math.sin(dlambda/2)**2
    return 2 * R * math.atan2(math.sqrt(a), math.sqrt(1-a))

def _clean_quotes(s: str) -> str:
    return re.sub(r'["\']', '', str(s)).strip()

def _parse_timestamp_series(s: pd.Series) -> pd.Series:
    num = pd.to_numeric(s, errors="coerce")
    if num.notna().sum() >= max(3, int(0.5 * len(s))):
        med = float(num.dropna().median())
        unit = "s" if med < 1e12 else "ms"
        return pd.to_datetime(num, unit=unit, utc=True, errors="coerce")
    ts = pd.to_datetime(s, errors="coerce", utc=True)
    if ts.notna().any() and (ts.dt.year.dropna().median() < 1980) and num.notna().any():
        med = float(num.dropna().median())
        unit = "s" if med < 1e12 else "ms"
        ts = pd.to_datetime(num, unit=unit, utc=True, errors="coerce")
    return ts

def detect_columns(df: pd.DataFrame) -> Tuple[Optional[str], Optional[str], Optional[str], Optional[str], Optional[str], Optional[str]]:
    cols = {c.lower().strip(): c for c in df.columns}
    lat = next((cols[c] for c in ["lat", "latitude", "y"] if c in cols), None)
    lon = next((cols[c] for c in ["lon", "lng", "long", "longitude", "x"] if c in cols), None)
    latlng_col = cols.get("latlng")
    time_col = next((cols[c] for c in ["timestamp", "time", "datetime", "date"] if c in cols), None)
    elevation_col = next((cols[c] for c in ["elevation", "alt", "altitude", "ele", "height"] if c in cols), None)
    odo_col = next((cols[c] for c in ["odometer", "odo", "distance"] if c in cols), None)
    return lat, lon, latlng_col, time_col, elevation_col, odo_col

def parse_csv(file_bytes: bytes) -> pd.DataFrame:
    buf = io.BytesIO(file_bytes)
    df = pd.read_csv(buf, sep=None, engine="python")
    lat, lon, latlng_col, time_col, elevation_col, odo_col = detect_columns(df)

    # latlng -> lat/lon
    if latlng_col is not None and (lat is None or lon is None):
        latlon = df[latlng_col].astype(str).str.split(",", n=1, expand=True)
        df["__lat"] = pd.to_numeric(latlon[0].map(_clean_quotes), errors="coerce")
        df["__lon"] = pd.to_numeric(latlon[1].map(_clean_quotes), errors="coerce")
        lat, lon = "__lat", "__lon"

    if lat is None or lon is None:
        raise ValueError("–ù–µ –Ω–∞–π–¥–µ–Ω—ã –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã. –ù—É–∂–Ω—ã lat/lon –∏–ª–∏ –æ–¥–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ latlng.")

    out = pd.DataFrame({
        "lat": pd.to_numeric(df[lat], errors="coerce"),
        "lon": pd.to_numeric(df[lon], errors="coerce"),
    })

    if time_col is not None:
        out["timestamp"] = _parse_timestamp_series(df[time_col])
    else:
        out["timestamp"] = pd.NaT

    out["elevation"] = pd.to_numeric(df[elevation_col], errors="coerce") if elevation_col else np.nan
    out["odometer"]  = pd.to_numeric(df[odo_col], errors="coerce") if odo_col else np.nan
    return out

def parse_gpx(file_bytes: bytes) -> pd.DataFrame:
    import gpxpy
    gpx = gpxpy.parse(io.StringIO(file_bytes.decode("utf-8", errors="ignore")))
    rows = []
    for track in gpx.tracks:
        for seg in track.segments:
            for p in seg.points:
                rows.append({
                    "lat": p.latitude, "lon": p.longitude,
                    "timestamp": pd.to_datetime(p.time, utc=True) if p.time else pd.NaT,
                    "elevation": p.elevation if p.elevation is not None else np.nan,
                    "odometer": np.nan,
                })
    for w in gpx.waypoints:
        rows.append({
            "lat": w.latitude, "lon": w.longitude,
            "timestamp": pd.to_datetime(getattr(w, "time", None), utc=True, errors="coerce") if getattr(w, "time", None) else pd.NaT,
            "elevation": getattr(w, "elevation", np.nan) if getattr(w, "elevation", None) is not None else np.nan,
            "odometer": np.nan,
        })
    if not rows:
        raise ValueError("–í GPX –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —Ç–æ—á–µ–∫.")
    return pd.DataFrame(rows)

def parse_geojson(file_bytes: bytes) -> pd.DataFrame:
    geo = json.loads(file_bytes.decode("utf-8", errors="ignore"))
    rows = []
    def add_point(coord, props):
        lon, lat = coord[0], coord[1]
        t = pd.NaT; elev = np.nan
        if isinstance(props, dict):
            if "time" in props: t = pd.to_datetime(props["time"], errors="coerce", utc=True)
            if "timestamp" in props: t = pd.to_datetime(props["timestamp"], errors="coerce", utc=True)
            if "elevation" in props: elev = pd.to_numeric(props["elevation"], errors="coerce")
        rows.append({"lat": lat, "lon": lon, "timestamp": t, "elevation": elev, "odometer": np.nan})
    def handle_geom(geom, props):
        if geom["type"] == "Point":
            add_point(geom["coordinates"], props)
        elif geom["type"] == "LineString":
            for c in geom["coordinates"]: add_point(c, props)
        elif geom["type"] == "MultiLineString":
            for line in geom["coordinates"]:
                for c in line: add_point(c, props)
    if geo.get("type") == "FeatureCollection":
        for f in geo["features"]: handle_geom(f["geometry"], f.get("properties", {}))
    elif geo.get("type") in ("Feature",):
        handle_geom(geo["geometry"], geo.get("properties", {}))
    else:
        handle_geom(geo, {})
    if not rows: raise ValueError("–í GeoJSON –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–æ—á–∫–∏.")
    return pd.DataFrame(rows)

def preprocess_track(df: pd.DataFrame) -> pd.DataFrame:
    df = df.dropna(subset=["lat", "lon"])
    df = df[(df["lat"].between(-90, 90)) & (df["lon"].between(-180, 180))].copy()
    if df["timestamp"].notna().any():
        df = df.sort_values(by=["timestamp"], kind="mergesort")
    df.reset_index(drop=True, inplace=True)
    return df

def _format_hms(hours: float) -> str:
    if not isinstance(hours, (int, float)) or not np.isfinite(hours):
        return "‚Äî"
    total_seconds = int(round(hours * 3600))
    h = total_seconds // 3600
    m = (total_seconds % 3600) // 60
    s = total_seconds % 60
    return f"{h:d}:{m:02d}:{s:02d}"

def compute_metrics(df: pd.DataFrame, prefer_source: str = "auto"):
    """
    –†–∞—Å—á–∏—Ç—ã–≤–∞–µ—Ç:
      - seg_dist_km, seg_dt_h, speed_kmh
      - cum_km
      - total_km, duration_h, avg_speed_kmh, max_speed_kmh
    –ò—Å—Ç–æ—á–Ω–∏–∫ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è:
      auto: –ø–æ –æ–¥–æ–º–µ—Ç—Ä—É, –µ—Å–ª–∏ –µ—Å—Ç—å –∞–¥–µ–∫–≤–∞—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –∏–Ω–∞—á–µ GPS
      gps: —Ç–æ–ª—å–∫–æ haversine
      odo: —Ç–æ–ª—å–∫–æ –æ–¥–æ–º–µ—Ç—Ä (—Å –∞–≤—Ç–æ-–º–∞—Å—à—Ç–∞–±–æ–º –º‚Üí–∫–º –ø–æ –º–µ–¥–∏–∞–Ω–µ)
    """
    n = len(df)
    seg_dt_h = np.zeros(n)
    # –≤—Ä–µ–º—è —Å–µ–≥–º–µ–Ω—Ç–∞
    for i in range(1, n):
        t1, t2 = df.at[i-1, "timestamp"], df.at[i, "timestamp"]
        if pd.notna(t1) and pd.notna(t2):
            seg_dt_h[i] = max((t2 - t1).total_seconds(), 0) / 3600.0

    # GPS —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
    gps_dist = np.zeros(n)
    for i in range(1, n):
        gps_dist[i] = haversine_km(df.at[i-1,"lat"], df.at[i-1,"lon"], df.at[i,"lat"], df.at[i,"lon"])

    # –û–¥–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è (–∫–∞–∫ –µ—Å—Ç—å)
    odo_dist_raw = np.full(n, np.nan)
    if "odometer" in df.columns and df["odometer"].notna().sum() >= 2:
        od = df["odometer"].astype(float).to_numpy()
        d = np.diff(od, prepend=np.nan)
        # –ø–µ—Ä–≤—ã–π —Å–µ–≥–º–µ–Ω—Ç –Ω–µ—Ç –∑–Ω–∞—á–µ–Ω–∏—è, –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ/—Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∏–µ —Å–∫–∞—á–∫–∏ -> NaN
        d[0] = np.nan
        d[d < 0] = np.nan  # —Å–±—Ä–æ—Å –æ–¥–æ–º–µ—Ç—Ä–∞
        odo_dist_raw = d

    # –í—ã–±–æ—Ä –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –∏ –Ω–æ—Ä–º–∏—Ä–æ–≤–∫–∞ –æ–¥–æ–º–µ—Ç—Ä–∞ (–º –∏–ª–∏ –∫–º)
    seg_dist_km = gps_dist.copy()
    used_source = "gps"
    if prefer_source in ("odo", "auto") and np.nanmax(odo_dist_raw) > 0 and np.nanmean(odo_dist_raw) > 0:
        # –ø–æ–ø—ã—Ç–∫–∞ –ø–æ–Ω—è—Ç—å –µ–¥–∏–Ω–∏—Ü—ã –ø–æ –æ—Ç–Ω–æ—à–µ–Ω–∏—é –∫ GPS (–º–µ–¥–∏–∞–Ω–∞ –ø–æ –≤–∞–ª–∏–¥–Ω—ã–º —Å–µ–≥–º–µ–Ω—Ç–∞–º)
        common_mask = (~np.isnan(odo_dist_raw)) & (gps_dist > 0)
        scale = np.nan
        if np.any(common_mask):
            med_odo = float(np.nanmedian(odo_dist_raw[common_mask]))
            med_gps = float(np.nanmedian(gps_dist[common_mask]))
            if med_gps > 0:
                scale = med_odo / med_gps
        # –µ—Å–ª–∏ –ø–æ—Ö–æ–∂–µ –Ω–∞ –º–µ—Ç—Ä—ã (–æ–∫–æ–ª–æ *1000), –¥–µ–ª–∏–º –Ω–∞ 1000
        if np.isfinite(scale) and 100 <= scale <= 2000:
            odo_dist_km = odo_dist_raw / 1000.0
        else:
            odo_dist_km = odo_dist_raw

        if prefer_source == "odo":
            seg_dist_km = np.nan_to_num(odo_dist_km, nan=0.0)
            used_source = "odom"
        else:  # auto: –æ–¥–æ–º–µ—Ç—Ä, –µ—Å–ª–∏ –¥–æ–ª—è –≤–∞–ª–∏–¥–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –ø—Ä–∏–ª–∏—á–Ω–∞—è
            valid_ratio = np.isfinite(odo_dist_km).sum() / max(1, n)
            if valid_ratio >= 0.5:  # –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–æ–ª–æ–≤–∏–Ω—ã —Å–µ–≥–º–µ–Ω—Ç–æ–≤
                seg_dist_km = np.nan_to_num(odo_dist_km, nan=0.0)
                used_source = "odom"
            else:
                seg_dist_km = gps_dist
                used_source = "gps"
    elif prefer_source == "gps":
        seg_dist_km = gps_dist
        used_source = "gps"

    with np.errstate(divide="ignore", invalid="ignore"):
        speed_kmh = np.where(seg_dt_h > 0, seg_dist_km / seg_dt_h, np.nan)

    df["seg_dist_km"] = seg_dist_km
    df["seg_dt_h"] = seg_dt_h
    df["speed_kmh"] = speed_kmh
    df["cum_km"] = np.cumsum(seg_dist_km)
    df["seg_dt_s"] = (seg_dt_h * 3600).round().astype("int64")

    total_km = float(np.nansum(seg_dist_km))
    duration_h = float(np.nansum(seg_dt_h)) if np.isfinite(np.nansum(seg_dt_h)) else np.nan
    avg_speed = float(total_km / duration_h) if duration_h and duration_h > 0 else np.nan
    max_speed = float(np.nanmax(speed_kmh)) if np.isfinite(np.nanmax(speed_kmh)) else np.nan

    elev_gain = elev_loss = np.nan
    if df["elevation"].notna().any():
        de = np.diff(df["elevation"].astype(float).to_numpy())
        elev_gain = float(np.sum(de[de > 0])) if de.size else np.nan
        elev_loss = float(-np.sum(de[de < 0])) if de.size else np.nan

    return {
        "points": int(n),
        "total_km": total_km,
        "duration_h": duration_h,
        "avg_speed_kmh": avg_speed,
        "max_speed_kmh": max_speed,
        "elev_gain": elev_gain,
        "elev_loss": elev_loss,
        "used_source": used_source,
    }, df

def to_geojson_points(df: pd.DataFrame) -> dict:
    feats = []
    for _, r in df.iterrows():
        props = {}
        if pd.notna(r.get("timestamp", pd.NaT)): props["time"] = pd.to_datetime(r["timestamp"]).isoformat()
        if pd.notna(r.get("elevation", np.nan)): props["elevation"] = float(r["elevation"])
        feats.append({"type":"Feature","geometry":{"type":"Point","coordinates":[float(r["lon"]), float(r["lat"])]},"properties":props})
    return {"type":"FeatureCollection","features":feats}

# ---------------------------
# UI (—Ç–æ–ª—å–∫–æ OpenStreetMap; –Ω—É–º–µ—Ä–∞—Ü–∏—è –∏ –ø–æ–≤—ã—à–µ–Ω–Ω–∞—è –∑–∞–º–µ—Ç–Ω–æ—Å—Ç—å —Ç–æ—á–µ–∫)
# ---------------------------

st.set_page_config(page_title="–ú–∞—Ä—à—Ä—É—Ç –ø–æ —Ç–æ—á–∫–∞–º", layout="wide")
st.title("üó∫Ô∏è –ú–∞—Ä—à—Ä—É—Ç –ø–æ —Ç–æ—á–∫–∞–º ‚Äî OpenStreetMap (–Ω—É–º–µ—Ä–∞—Ü–∏—è —Ç–æ—á–µ–∫)")

with st.sidebar:
    st.header("–§–∞–π–ª")
    file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV/GPX/GeoJSON", type=["csv","gpx","geojson","json"])
    st.header("–û–ø—Ü–∏–∏")
    dist_source = st.radio(
        "–ò—Å—Ç–æ—á–Ω–∏–∫ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è",
        ["–ê–≤—Ç–æ", "GPS", "–û–¥–æ–º–µ—Ç—Ä"],
        index=0,
        help="–ê–≤—Ç–æ: –±–µ—Ä—ë–º –æ–¥–æ–º–µ—Ç—Ä, –µ—Å–ª–∏ –æ–Ω –ø–æ–ª–æ–Ω, –∏–Ω–∞—á–µ –≤—ã—á–∏—Å–ª—è–µ–º –ø–æ GPS (haversine)."
    )
    animate = st.checkbox("–ê–Ω–∏–º–∞—Ü–∏—è –ª–∏–Ω–∏–∏ (AntPath)", True)
    time_slider = st.checkbox("–¢–∞–π–º-—Å–ª–∞–π–¥–µ—Ä (–µ—Å–ª–∏ –µ—Å—Ç—å –≤—Ä–µ–º—è)", True)

if not file:
    st.info("–î–ª—è CSV –∫–æ–ª–æ–Ω–∫–∞ **latlng** –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ä–∞–∑–±–∏–≤–∞–µ—Ç—Å—è –Ω–∞ **lat, lon**. –í—Å–µ —Ç–æ—á–∫–∏ –±—É–¥—É—Ç –ø—Ä–æ–Ω—É–º–µ—Ä–æ–≤–∞–Ω—ã. –¢–∞–∫–∂–µ —Å—á–∏—Ç–∞—é—Ç—Å—è **–≤—Ä–µ–º—è, –∫–∏–ª–æ–º–µ—Ç—Ä–∞–∂ –∏ —Å–∫–æ—Ä–æ—Å—Ç—å** (–µ—Å–ª–∏ –µ—Å—Ç—å timestamp).")
    st.stop()

with st.spinner("–†–∞–∑–±–æ—Ä —Ñ–∞–π–ª–∞‚Ä¶"):
    raw = file.read()
    ext = file.name.lower().split(".")[-1]
    if ext == "csv":
        df = parse_csv(raw)
    elif ext == "gpx":
        df = parse_gpx(raw)
    elif ext in ("geojson", "json"):
        df = parse_geojson(raw)
    else:
        df = parse_csv(raw)

    df = preprocess_track(df)
    if len(df) < 2:
        st.error("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ—á–µ–∫.")
        st.stop()

    prefer = {"–ê–≤—Ç–æ":"auto","GPS":"gps","–û–¥–æ–º–µ—Ç—Ä":"odo"}[dist_source]
    metrics, df = compute_metrics(df, prefer_source=prefer)

# –ö–∞—Ä—Ç–∞ (—Ç–æ–ª—å–∫–æ OpenStreetMap)
center = [float(df["lat"].mean()), float(df["lon"].mean())]
m = folium.Map(location=center, tiles="OpenStreetMap", zoom_start=13, control_scale=True)

coords = df[["lat","lon"]].to_numpy().tolist()

# –õ–∏–Ω–∏—è –º–∞—Ä—à—Ä—É—Ç–∞ + —Å—Ç—Ä–µ–ª–∫–∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è
poly = folium.PolyLine(coords, weight=6, opacity=0.95, color="#1976d2", tooltip="–ú–∞—Ä—à—Ä—É—Ç")
poly.add_to(m)
PolyLineTextPath(
    poly, "‚ñ∂", repeat=True, offset=10,
    attributes={"fill": "#1976d2", "font-weight": "bold", "font-size": "16"}
).add_to(m)

# –ù—É–º–µ—Ä–∞—Ü–∏—è: —è—Ä–∫–∏–µ –∫—Ä—É–≥–ª—ã–µ –±–µ–π–¥–∂–∏ —Å –Ω–æ–º–µ—Ä–æ–º
def numbered_marker(lat, lon, num, is_last=False, color_bg="#1e90ff"):
    if num == 1:
        color_bg = "#2ecc71"  # —Å—Ç–∞—Ä—Ç: –∑–µ–ª—ë–Ω—ã–π
    if is_last:
        color_bg = "#e74c3c"  # —Ñ–∏–Ω–∏—à: –∫—Ä–∞—Å–Ω—ã–π
    ts = df.at[num-1, "timestamp"]
    tip_time = f" ‚Ä¢ {pd.to_datetime(ts).isoformat()}" if pd.notna(ts) else ""
    seg_d = df.at[num-1, "seg_dist_km"] if num-1 >= 0 else np.nan
    seg_v = df.at[num-1, "speed_kmh"] if num-1 >= 0 else np.nan
    cum_d = df.at[num-1, "cum_km"] if num-1 >= 0 else np.nan
    tooltip = f"#{num}{tip_time}"
    if np.isfinite(seg_d):
        tooltip += f" ‚Ä¢ Œî {seg_d:.3f} –∫–º"
    if np.isfinite(seg_v):
        tooltip += f" ‚Ä¢ v {seg_v:.1f} –∫–º/—á"
    if np.isfinite(cum_d):
        tooltip += f" ‚Ä¢ Œ£ {cum_d:.3f} –∫–º"

    html = f"""
    <div style="
        background:{color_bg};
        color:#fff;
        border:2px solid #000;
        border-radius:50%;
        width:26px;height:26px;
        line-height:22px;
        text-align:center;
        font-weight:700;
        font-size:13px;
        box-shadow:0 0 0 2px rgba(255,255,255,0.9);
    ">{num}</div>
    """
    return folium.Marker(
        [lat, lon],
        icon=folium.DivIcon(html=html, icon_size=(26,26), icon_anchor=(13,13)),
        tooltip=tooltip
    )

# –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ –ø—Ä–æ–Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ç–æ—á–∫–∏
N = len(coords)
for i, (lat, lon) in enumerate(coords, start=1):
    is_last = (i == N)
    numbered_marker(lat, lon, i, is_last=is_last).add_to(m)

# –û—Ç–¥–µ–ª—å–Ω–æ –ø–æ–º–µ—Ç–∫–∏ —Å—Ç–∞—Ä—Ç/—Ñ–∏–Ω–∏—à (–∏–∫–æ–Ω–∫–∏ + –ø–æ–¥—Å–∫–∞–∑–∫–∏)
folium.Marker(coords[0], tooltip="–°—Ç–∞—Ä—Ç (‚Ññ1)", icon=folium.Icon(color="green")).add_to(m)
folium.Marker(coords[-1], tooltip=f"–§–∏–Ω–∏—à (‚Ññ{N})", icon=folium.Icon(color="red")).add_to(m)

# –ê–Ω–∏–º–∞—Ü–∏—è –∏ —Ç–∞–π–º-—Å–ª–∞–π–¥–µ—Ä
if animate:
    AntPath(coords, delay=800, dash_array=[10,20]).add_to(m)
if time_slider and df["timestamp"].notna().any():
    ts_points = to_geojson_points(df)
    TimestampedGeoJson(
        ts_points,
        period="PT1S",
        add_last_point=True,
        duration="PT5S",
        transition_time=200,
        loop=False,
        auto_play=False
    ).add_to(m)

st_folium(m, width=1350, height=800, returned_objects=[])

# ---- –ò—Ç–æ–≥–∏
st.subheader("–ò—Ç–æ–≥–∏")
col1, col2, col3, col4, col5 = st.columns(5)
col1.metric("–ö–∏–ª–æ–º–µ—Ç—Ä–∞–∂", f"{metrics['total_km']:.3f} –∫–º")
col2.metric("–í—Ä–µ–º—è", _format_hms(metrics["duration_h"]))
col3.metric("–°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å", f"{metrics['avg_speed_kmh']:.1f} –∫–º/—á" if np.isfinite(metrics["avg_speed_kmh"]) else "‚Äî")
col4.metric("–ú–∞–∫—Å. —Å–∫–æ—Ä–æ—Å—Ç—å", f"{metrics['max_speed_kmh']:.1f} –∫–º/—á" if np.isfinite(metrics["max_speed_kmh"]) else "‚Äî")
col5.metric("–ò—Å—Ç–æ—á–Ω–∏–∫ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è", "–û–¥–æ–º–µ—Ç—Ä" if metrics["used_source"]=="odom" else "GPS")

if not df["timestamp"].notna().any():
    st.warning("–í–æ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ ‚Äî –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏ —Å–∫–æ—Ä–æ—Å—Ç—å –ø–æ—Å–µ–≥–º–µ–Ω—Ç–Ω–æ –Ω–µ –≤—ã—á–∏—Å–ª—è—é—Ç—Å—è.")

with st.expander("–ü–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ –æ—á–∏—â–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –º–µ—Ç—Ä–∏–∫ (–¥–æ 50)"):
    show_cols = ["timestamp","lat","lon","elevation","odometer","seg_dist_km","seg_dt_s","speed_kmh","cum_km"]
    st.dataframe(df[show_cols].head(50))

# –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç
csv_out = df.to_csv(index=False).encode("utf-8")
st.download_button("‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å –æ–±–æ–≥–∞—â—ë–Ω–Ω—ã–π CSV", data=csv_out, file_name="track_with_metrics.csv", mime="text/csv")
